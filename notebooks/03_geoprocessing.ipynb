{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geoprocessing\n",
    "\n",
    "---\n",
    "\n",
    "This notebook includes the code to spatially join the Nightfire data points to the Basin Regions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Geoprocessing\" data-toc-modified-id=\"Geoprocessing-1\">Geoprocessing</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#What-is-Geoprocessing?\" data-toc-modified-id=\"What-is-Geoprocessing?-1.0.1\">What is Geoprocessing?</a></span></li><li><span><a href=\"#Geoprocessing-Library-Selection\" data-toc-modified-id=\"Geoprocessing-Library-Selection-1.0.2\">Geoprocessing Library Selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Geopandas\" data-toc-modified-id=\"Geopandas-1.0.2.1\">Geopandas</a></span></li></ul></li></ul></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.1\">Imports</a></span></li><li><span><a href=\"#Code-from-Notebook-1,-needed-for-in-memory-objects-for-Geoprocessing-steps-below\" data-toc-modified-id=\"Code-from-Notebook-1,-needed-for-in-memory-objects-for-Geoprocessing-steps-below-1.2\">Code from Notebook 1, needed for in-memory objects for Geoprocessing steps below</a></span><ul class=\"toc-item\"><li><span><a href=\"#Glob-to-collect-the-Nightfire-files-from-2012-to-present-day\" data-toc-modified-id=\"Glob-to-collect-the-Nightfire-files-from-2012-to-present-day-1.2.1\">Glob to collect the Nightfire files from 2012 to present day</a></span></li></ul></li><li><span><a href=\"#Point-in-Polygon-Counts-via-Spatial-Join\" data-toc-modified-id=\"Point-in-Polygon-Counts-via-Spatial-Join-1.3\">Point-in Polygon Counts via Spatial Join</a></span><ul class=\"toc-item\"><li><span><a href=\"#Join-Features\" data-toc-modified-id=\"Join-Features-1.3.1\">Join Features</a></span></li><li><span><a href=\"#Execute-the-Spatial-Join\" data-toc-modified-id=\"Execute-the-Spatial-Join-1.3.2\">Execute the Spatial Join</a></span></li></ul></li></ul></li><li><span><a href=\"#Next-Notebook\" data-toc-modified-id=\"Next-Notebook-2\">Next Notebook</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Geoprocessing?\n",
    "\n",
    "Very broadly, **Geoprocessing** is any operation involving geospatial data or methods. The Geographic Information Systems (GIS) software company Esri refers to it as \"[Computing with geographic data.](http://webhelp.esri.com/arcgisdesktop/9.3/index.cfm?TopicName=Comparing_Geoprocessing_and_Spatial_Analysis)\" It is commonly misused interchangeably with the term [Spatial Analysis](http://webhelp.esri.com/arcgisdesktop/9.3/index.cfm?TopicName=Comparing_Geoprocessing_and_Spatial_Analysi). However, Spatial Analysis includes the interpretation of the results of Geoprocessing. Spatial Analysis has more in common with the **[Data Science Process](https://medium.springboard.com/the-data-science-process-the-complete-laymans-guide-to-what-a-data-scientist-actually-does-ca3e166b7c67)**, while Geoprocessing has more in common joining, grouping and aggregating data steps in a typical data science project workflow. \n",
    "\n",
    "Professor Jochen Albrecht defines Geoprocessing as;\n",
    "> _...any GIS operation used to manipulate data. A typical geoprocessing operation takes an input dataset, performs an operation on that dataset, and returns the result of the operation as an output dataset, also referred to as derived data. Common geoprocessing operations are geographic feature overlay, feature selection and analysis, topology processing, and data conversion. Geoprocessing allows you to define, manage, and analyze geographic information used to make decisions._ [Jochen Albrecht](http://www.geography.hunter.cuny.edu/~jochen/GTECH361/lectures/lecture12/concepts/01%20What%20is%20geoprocessing.htm)\n",
    "\n",
    "### Geoprocessing Library Selection\n",
    "\n",
    "There are several Geoprocessing libraries and technologies. A few notable open source ones are;\n",
    "\n",
    "* [PostGIS](https://postgis.net/) - Spatially Enabled PostgreSQL \n",
    "* [GeoPandas](https://geopandas.org/) - Pandas Extended with [Shapely](https://shapely.readthedocs.io/en/latest/)\n",
    "* [Arcpy](https://pro.arcgis.com/en/pro-app/arcpy/get-started/what-is-arcpy-.htm) - Esri's Python site package\n",
    "* [PyQGIS](https://docs.qgis.org/testing/en/docs/pyqgis_developer_cookbook/) - [QGIS](https://www.qgis.org/en/site/)'s Python Package\n",
    "\n",
    "\n",
    "#### Geopandas\n",
    "\n",
    "This project leverages [GeoPandas](https://geopandas.org/) as its very easy to leverage in the `pandas` environment and data science workflow. Additionally, outside of reading and writing geospatial files and objects, this project only leverages one geoprocessing function, [spatial join](https://geopandas.org/reference/geopandas.sjoin.html). \n",
    "\n",
    "> _GeoPandas is an open source project to make working with geospatial\n",
    "data in python easier.  GeoPandas extends the datatypes used by\n",
    "`pandas` to allow spatial operations on geometric types.  Geometric\n",
    "operations are performed by `shapely`.  Geopandas further depends on\n",
    "`fiona` for file access and `descartes` and `matplotlib` for plotting._ Source: [GeoPandas](https://geopandas.org/) \n",
    "\n",
    "**Description**\n",
    "\n",
    "> _The goal of GeoPandas is to make working with geospatial data in\n",
    "python easier.  It combines the capabilities of pandas and shapely,\n",
    "providing geospatial operations in pandas and a high-level interface\n",
    "to multiple geometries to shapely.  GeoPandas enables you to easily do\n",
    "operations in python that would otherwise require a spatial database\n",
    "such as PostGIS._ Source: [GeoPandas](https://geopandas.org/) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.tools import read_json, get_current_time\n",
    "from capstone.etl.viirs_join_basins import viirs_join_basins, compile_basin_data\n",
    "from capstone.etl.census_parse import parse_census\n",
    "from capstone.etl.census_retrieval import census_retrieval\n",
    "from capstone.etl.generate_basins import generate_us_basins\n",
    "from capstone.etl.eia_retrieval import eia_retrieval\n",
    "from capstone.etl.eia_parse import eia_parse_county, eia_parse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_json('../capstone/config.json')\n",
    "\n",
    "current_date = get_current_time('yyyymmdd')\n",
    "\n",
    "wd = f\"{config['workspace_directory']}/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_colors_hex = {  # manually defined dictionary of EIA basin-level standardized colors \n",
    "    \"Anadarko Region\":    \"#2BA2CF\", \n",
    "    \"Appalachia Region\":  \"#769F5D\",\n",
    "    \"Bakken Region\":      \"#F6C432\", \n",
    "    \"Eagle Ford Region\":  \"#48366B\", \n",
    "    \"Haynesville Region\": \"#807B8F\",\n",
    "    \"Niobrara Region\":    \"#9D3341\",\n",
    "    \"Permian Region\":     \"#6F4B27\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from Notebook 1, needed for in-memory objects for Geoprocessing steps below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " parse eia data\n",
      "    for anadarko region\n",
      "    for appalachia region\n",
      "    for bakken region\n",
      "    for eagle ford region\n",
      "    for haynesville region\n",
      "    for niobrara region\n",
      "    for permian region\n",
      "generating us basins\n",
      "    permian region\n",
      "    appalachia region\n",
      "    haynesville region\n",
      "    eagle ford region\n",
      "    anadarko region\n",
      "    niobrara region\n",
      "    bakken region\n"
     ]
    }
   ],
   "source": [
    "census_shp = census_retrieval(f\"{wd}/input/census\")\n",
    "census = gpd.read_file(census_shp)\n",
    "census.columns = [c.lower() for c in census.columns]\n",
    "\n",
    "eia_xls = eia_retrieval(f\"{wd}/input/eia\")\n",
    "eia_cnty = eia_parse_county(eia_xls)\n",
    "eia_data = eia_parse_data(eia_xls)  # parse the target variable(s) data\n",
    "\n",
    "census_gdf = parse_census(census_shp)\n",
    "basins_list, all_basins = generate_us_basins(\n",
    "    census_gdf,\n",
    "    eia_cnty,\n",
    "    f\"{wd}/input/basins\",\n",
    ")  # this code creates individual files for basin geographies as well as an all_basins geography file/object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glob to collect the Nightfire files from 2012 to present day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 2.1c files: 2095\n",
      "Total 3.0 files: 833\n"
     ]
    }
   ],
   "source": [
    "# get lists of all the retrieved viirs data for both 2.1c and 3.0 viirs\n",
    "\n",
    "viirs_2_1c_files = glob.glob(f\"{wd}/input/viirs21c/*.csv\")  # get viirs\n",
    "viirs_2_1c_files.sort()  # sort so dates are consecutive for tracking\n",
    "\n",
    "print(f'Total 2.1c files: {len(viirs_2_1c_files)}')\n",
    "\n",
    "viirs_3_0_files = glob.glob(f\"{wd}/input/viirs30/*.csv\")  # get viirs files\n",
    "viirs_3_0_files.sort()  # sort so dates are consecutive for tracking\n",
    "\n",
    "print(f'Total 3.0 files: {len(viirs_3_0_files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point-in Polygon Counts via Spatial Join\n",
    "\n",
    "While Join Features tool was not used (rather GeoPandas S-Join for Spatial Join), this illustration better shows how a given geography 2d or 3d polygon, is intersected with points, we can count those features inside. \n",
    "\n",
    "### Join Features\n",
    "\n",
    "Description form Esri documentation:\n",
    "\n",
    "> Joins attributes from one layer to another based on spatial, temporal, or attribute relationships, or a combination of those relationships. [https://pro.arcgis.com/en/pro-app/tool-reference/geoanalytics-desktop/join-features.htm](https://pro.arcgis.com/en/pro-app/tool-reference/geoanalytics-desktop/join-features.htm)\n",
    "\n",
    "[![join](https://pro.arcgis.com/en/pro-app/tool-reference/geoanalytics-desktop/GUID-EB8FA998-105A-4D93-93E3-5FAA1057137D-web.png)](https://pro.arcgis.com/en/pro-app/tool-reference/geoanalytics-desktop/GUID-EB8FA998-105A-4D93-93E3-5FAA1057137D-web.png)\n",
    "\n",
    "\n",
    "Geopandas code inside `tools.geoprocessing.py` which is used inside `viirs_join_basins(...)`  in this project repository:\n",
    "```python\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "def point_in_polygon(point_gdf, poly_gdf):\n",
    "    return gpd.sjoin(\n",
    "        point_gdf,\n",
    "        poly_gdf,\n",
    "        how=\"inner\",\n",
    "        op='intersects',  # warning CRS of frames do not match\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the Spatial Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join \n",
    "viirs_join_basins( \n",
    "    wd,\n",
    "    all_basins,\n",
    "    viirs_2_1c_files,\n",
    "    '21c',\n",
    ")   # spatially join viirs 2.1c to basins geometries\n",
    "\n",
    "viirs_join_basins(\n",
    "    wd,\n",
    "    all_basins,\n",
    "    viirs_3_0_files,\n",
    "    '30',\n",
    ")  # spatially join viirs 3.0 to basins geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    20130101\n",
      "    20140101\n",
      "    20150101\n",
      "    20160101\n",
      "    20170101\n",
      "    20180101\n",
      "    20190101\n",
      "    20200101\n"
     ]
    }
   ],
   "source": [
    "basins_int_viirs_21c = compile_basin_data(wd, '21c')\n",
    "basins_int_viirs_30  = compile_basin_data(wd, '30')  \n",
    "# above function saves master compiled 2.1c and 3.0 files, prints every january first per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009001, 129)\n",
      "(528056, 46)\n"
     ]
    }
   ],
   "source": [
    "print(basins_int_viirs_21c.shape)\n",
    "print(basins_int_viirs_30.shape)  # check the shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geoprocessing is complete joining all region data to the Nightfire data files. \n",
    "\n",
    "![](../images/bakken_nightfire_2017.gif)\n",
    "Each of these points layers for each of the dates from 2012-03 to present day (all of 2017 in the image above) are intersected with the region information so the basin region data can be appended to the point dataset and then aggregated in the [Feature Engineering and Exploratory Data Analysis of Processed Data](https://git.generalassemb.ly/danielmartinsheehan/capstone/blob/master/notebooks/04_feature_engineernig_and_exploratory_data_analysis_processed_data.ipynb) notebook. The animated image above is also generated in that notebook. \n",
    "\n",
    "# Next Notebook\n",
    "\n",
    "[Feature Engineering and Exploratory Data Analysis of Processed Data](https://git.generalassemb.ly/danielmartinsheehan/capstone/blob/master/notebooks/04_feature_engineering_and_exploratory_data_analysis_processed_data.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
